{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1394149687539972430\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3155650150\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6982757343084970374\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the necessary libraries, modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd # Pandas library for reading '.csv' files as dataframes\n",
    "import numpy as np  # Numpy library for creating and modifying arrays.\n",
    "import tensorflow\n",
    "from keras.layers import Dense, SimpleRNN, GRU, LSTM, Embedding # Import layers from Keras\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43694, 9)\n",
      "Index(['title', 'body', 'ticket_type', 'category', 'sub_category1',\n",
      "       'sub_category2', 'business_service', 'urgency', 'impact'],\n",
      "      dtype='object')\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>ticket_type</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category1</th>\n",
       "      <th>sub_category2</th>\n",
       "      <th>business_service</th>\n",
       "      <th>urgency</th>\n",
       "      <th>impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car allowance record</td>\n",
       "      <td>october pm allowance record hello think july seems incorrect allowance record amount effective st july inserted about employees sheet attached applies employees possible records corrected by script incorrect each employees record thanks</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project resources decommission write</td>\n",
       "      <td>october pm resources decommission hello please log several calls resources decommission please log call every resource needed closed questions please let thank best regards senior engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>access to the internal</td>\n",
       "      <td>thursday hello writing ask question regarding right zone awards application station please provide urgent because preparing demo lot application functionalities based kind regards developer</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new project code fusion</td>\n",
       "      <td>code hi please create code commercial kicking off client code requested vice president</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>password reset for</td>\n",
       "      <td>re available has assigned hi guys did till receive also work please status hello since then forward order per procedure please continue follow instructions dear please follow procedure unlock help her ahead best regards senior engineer tuesday pm available has assigned hi did remitted by yourself works nowhere also</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "0  car allowance record                   \n",
       "1  project resources decommission write   \n",
       "2  access to the internal                 \n",
       "3  new project code fusion                \n",
       "4  password reset for                     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                           body  \\\n",
       "0  october pm allowance record hello think july seems incorrect allowance record amount effective st july inserted about employees sheet attached applies employees possible records corrected by script incorrect each employees record thanks                                                                                   \n",
       "1  october pm resources decommission hello please log several calls resources decommission please log call every resource needed closed questions please let thank best regards senior engineer                                                                                                                                   \n",
       "2  thursday hello writing ask question regarding right zone awards application station please provide urgent because preparing demo lot application functionalities based kind regards developer                                                                                                                                  \n",
       "3  code hi please create code commercial kicking off client code requested vice president                                                                                                                                                                                                                                         \n",
       "4  re available has assigned hi guys did till receive also work please status hello since then forward order per procedure please continue follow instructions dear please follow procedure unlock help her ahead best regards senior engineer tuesday pm available has assigned hi did remitted by yourself works nowhere also   \n",
       "\n",
       "   ticket_type  category  sub_category1  sub_category2  business_service  \\\n",
       "0  1            4         3              0              40                 \n",
       "1  1            4         2              87             4                  \n",
       "2  1            6         22             7              41                 \n",
       "3  1            4         3              7              70                 \n",
       "4  1            4         2              88             4                  \n",
       "\n",
       "   urgency  impact  \n",
       "0  3        4       \n",
       "1  3        4       \n",
       "2  3        4       \n",
       "3  3        4       \n",
       "4  3        4       "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('Train.csv', encoding='latin-1') # Read the data as a DataFrame using Pandas\n",
    "raw_test_data = pd.read_csv('Validation.csv', encoding='latin-1')\n",
    "\n",
    "print(raw_data.shape) # Print the dimensions of train DataFrame\n",
    "print(raw_data.columns) # Print the column names of the DataFrame\n",
    "print('\\n')\n",
    "raw_data.head(5) # Print the top few records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43694, 9)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape\n",
    "#raw_data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# corr = raw_data.corr()\n",
    "# corr.style.background_gradient(cmap='coolwarm')\n",
    "# # 'RdBu_r' & 'BrBG' are other good diverging colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4855, 9)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the unique classes and their counts/frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[ 1487  6073  4975 31159]\n"
     ]
    }
   ],
   "source": [
    "# Print the unique classes and their counts/frequencies\n",
    "classes = np.unique(raw_data['urgency'], return_counts=True) # np.unique returns a tuple with class names and counts\n",
    "print(classes[0]) #Print the list of unique classes\n",
    "print(classes[1]) #Print the list of frequencies of the above classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    31159\n",
       "1    6073 \n",
       "2    4975 \n",
       "0    1487 \n",
       "Name: urgency, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(raw_data['urgency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting unstructured text to structured numeric form\n",
    "This includes:\n",
    "1. Tokenizing\n",
    "2. Converting sequence of words to sequence of word indeces\n",
    "3. Converting varing length sequences to fixed length sequences through padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_words = 10000\n",
    "seq_len = 50\n",
    "embedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_num_words)\n",
    "tokenizer.fit_on_texts(raw_data.body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_sequences(raw_data.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36,\n",
       " 2,\n",
       " 1974,\n",
       " 450,\n",
       " 6,\n",
       " 264,\n",
       " 24,\n",
       " 238,\n",
       " 967,\n",
       " 1974,\n",
       " 450,\n",
       " 687,\n",
       " 1417,\n",
       " 199,\n",
       " 24,\n",
       " 2566,\n",
       " 129,\n",
       " 444,\n",
       " 579,\n",
       " 33,\n",
       " 2489,\n",
       " 444,\n",
       " 114,\n",
       " 876,\n",
       " 1836,\n",
       " 21,\n",
       " 1263,\n",
       " 967,\n",
       " 141,\n",
       " 444,\n",
       " 450,\n",
       " 9]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>ticket_type</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category1</th>\n",
       "      <th>sub_category2</th>\n",
       "      <th>business_service</th>\n",
       "      <th>urgency</th>\n",
       "      <th>impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car allowance record</td>\n",
       "      <td>october pm allowance record hello think july seems incorrect allowance record amount effective st july inserted about employees sheet attached applies employees possible records corrected by script incorrect each employees record thanks</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project resources decommission write</td>\n",
       "      <td>october pm resources decommission hello please log several calls resources decommission please log call every resource needed closed questions please let thank best regards senior engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>access to the internal</td>\n",
       "      <td>thursday hello writing ask question regarding right zone awards application station please provide urgent because preparing demo lot application functionalities based kind regards developer</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new project code fusion</td>\n",
       "      <td>code hi please create code commercial kicking off client code requested vice president</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>password reset for</td>\n",
       "      <td>re available has assigned hi guys did till receive also work please status hello since then forward order per procedure please continue follow instructions dear please follow procedure unlock help her ahead best regards senior engineer tuesday pm available has assigned hi did remitted by yourself works nowhere also</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "0  car allowance record                   \n",
       "1  project resources decommission write   \n",
       "2  access to the internal                 \n",
       "3  new project code fusion                \n",
       "4  password reset for                     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                           body  \\\n",
       "0  october pm allowance record hello think july seems incorrect allowance record amount effective st july inserted about employees sheet attached applies employees possible records corrected by script incorrect each employees record thanks                                                                                   \n",
       "1  october pm resources decommission hello please log several calls resources decommission please log call every resource needed closed questions please let thank best regards senior engineer                                                                                                                                   \n",
       "2  thursday hello writing ask question regarding right zone awards application station please provide urgent because preparing demo lot application functionalities based kind regards developer                                                                                                                                  \n",
       "3  code hi please create code commercial kicking off client code requested vice president                                                                                                                                                                                                                                         \n",
       "4  re available has assigned hi guys did till receive also work please status hello since then forward order per procedure please continue follow instructions dear please follow procedure unlock help her ahead best regards senior engineer tuesday pm available has assigned hi did remitted by yourself works nowhere also   \n",
       "\n",
       "   ticket_type  category  sub_category1  sub_category2  business_service  \\\n",
       "0  1            4         3              0              40                 \n",
       "1  1            4         2              87             4                  \n",
       "2  1            6         22             7              41                 \n",
       "3  1            4         3              7              70                 \n",
       "4  1            4         2              88             4                  \n",
       "\n",
       "   urgency  impact  \n",
       "0  3        4       \n",
       "1  3        4       \n",
       "2  3        4       \n",
       "3  3        4       \n",
       "4  3        4       "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'please': 1,\n",
       " 'pm': 2,\n",
       " 'hi': 3,\n",
       " 'regards': 4,\n",
       " 'thank': 5,\n",
       " 'hello': 6,\n",
       " 'you': 7,\n",
       " 're': 8,\n",
       " 'thanks': 9,\n",
       " 'for': 10,\n",
       " 'sent': 11,\n",
       " 'kind': 12,\n",
       " 'help': 13,\n",
       " 'tuesday': 14,\n",
       " 'wednesday': 15,\n",
       " 'dear': 16,\n",
       " 'thursday': 17,\n",
       " 'friday': 18,\n",
       " 'best': 19,\n",
       " 'have': 20,\n",
       " 'by': 21,\n",
       " 'with': 22,\n",
       " 'can': 23,\n",
       " 'july': 24,\n",
       " 'engineer': 25,\n",
       " 'error': 26,\n",
       " 'has': 27,\n",
       " 'ext': 28,\n",
       " 'issue': 29,\n",
       " 'log': 30,\n",
       " 'be': 31,\n",
       " 'let': 32,\n",
       " 'attached': 33,\n",
       " 'date': 34,\n",
       " 'change': 35,\n",
       " 'october': 36,\n",
       " 'information': 37,\n",
       " 'we': 38,\n",
       " 'senior': 39,\n",
       " 'also': 40,\n",
       " 'november': 41,\n",
       " 'add': 42,\n",
       " 'form': 43,\n",
       " 'details': 44,\n",
       " 'name': 45,\n",
       " 'order': 46,\n",
       " 'your': 47,\n",
       " 'analyst': 48,\n",
       " 'access': 49,\n",
       " 'leaver': 50,\n",
       " 'update': 51,\n",
       " 'december': 52,\n",
       " 'number': 53,\n",
       " 'code': 54,\n",
       " 'could': 55,\n",
       " 'officer': 56,\n",
       " 'if': 57,\n",
       " 'site': 58,\n",
       " 'provide': 59,\n",
       " 'leave': 60,\n",
       " 'work': 61,\n",
       " 'march': 62,\n",
       " 'client': 63,\n",
       " 'create': 64,\n",
       " 'high': 65,\n",
       " 'report': 66,\n",
       " 'issues': 67,\n",
       " 'si': 68,\n",
       " 'or': 69,\n",
       " 'did': 70,\n",
       " 'but': 71,\n",
       " 'days': 72,\n",
       " 'february': 73,\n",
       " 'other': 74,\n",
       " 'manager': 75,\n",
       " 'more': 76,\n",
       " 'working': 77,\n",
       " 'cannot': 78,\n",
       " 'find': 79,\n",
       " 'how': 80,\n",
       " 'la': 81,\n",
       " 'administrator': 82,\n",
       " 'card': 83,\n",
       " 'assigned': 84,\n",
       " 'receive': 85,\n",
       " 'out': 86,\n",
       " 'confluence': 87,\n",
       " 'location': 88,\n",
       " 'importance': 89,\n",
       " 'user': 90,\n",
       " 'these': 91,\n",
       " 'when': 92,\n",
       " 'en': 93,\n",
       " 'action': 94,\n",
       " 'problem': 95,\n",
       " 'below': 96,\n",
       " 'phone': 97,\n",
       " 'take': 98,\n",
       " 'needed': 99,\n",
       " 'after': 100,\n",
       " 'received': 101,\n",
       " 'any': 102,\n",
       " 'required': 103,\n",
       " 'note': 104,\n",
       " 'link': 105,\n",
       " 'mailbox': 106,\n",
       " 'developer': 107,\n",
       " 'make': 108,\n",
       " 'his': 109,\n",
       " 'was': 110,\n",
       " 'monday': 111,\n",
       " 'submit': 112,\n",
       " 'floor': 113,\n",
       " 'possible': 114,\n",
       " 'old': 115,\n",
       " 'guys': 116,\n",
       " 'users': 117,\n",
       " 'hub': 118,\n",
       " 'rights': 119,\n",
       " 'lead': 120,\n",
       " 'which': 121,\n",
       " 'assign': 122,\n",
       " 'advise': 123,\n",
       " 'starter': 124,\n",
       " 'purchase': 125,\n",
       " 'id': 126,\n",
       " 'po': 127,\n",
       " 'upgrade': 128,\n",
       " 'about': 129,\n",
       " 'same': 130,\n",
       " 'because': 131,\n",
       " 'status': 132,\n",
       " 'there': 133,\n",
       " 'accounts': 134,\n",
       " 'mobile': 135,\n",
       " 'reports': 136,\n",
       " 'test': 137,\n",
       " 'ca': 138,\n",
       " 'today': 139,\n",
       " 'he': 140,\n",
       " 'each': 141,\n",
       " 'message': 142,\n",
       " 'need': 143,\n",
       " 'task': 144,\n",
       " 'under': 145,\n",
       " 'tester': 146,\n",
       " 'her': 147,\n",
       " 'ad': 148,\n",
       " 'process': 149,\n",
       " 'application': 150,\n",
       " 'head': 151,\n",
       " 'further': 152,\n",
       " 'kindly': 153,\n",
       " 'available': 154,\n",
       " 'one': 155,\n",
       " 'delete': 156,\n",
       " 'advised': 157,\n",
       " 'cards': 158,\n",
       " 'she': 159,\n",
       " 'ask': 160,\n",
       " 'ticket': 161,\n",
       " 'view': 162,\n",
       " 'approved': 163,\n",
       " 'va': 164,\n",
       " 'meeting': 165,\n",
       " 'annual': 166,\n",
       " 'item': 167,\n",
       " 'submitted': 168,\n",
       " 'back': 169,\n",
       " 'should': 170,\n",
       " 'approve': 171,\n",
       " 'approver': 172,\n",
       " 'care': 173,\n",
       " 'per': 174,\n",
       " 'next': 175,\n",
       " 'owner': 176,\n",
       " 'folder': 177,\n",
       " 'monitor': 178,\n",
       " 'some': 179,\n",
       " 'tried': 180,\n",
       " 'well': 181,\n",
       " 'updates': 182,\n",
       " 'again': 183,\n",
       " 'request': 184,\n",
       " 'created': 185,\n",
       " 'added': 186,\n",
       " 'approval': 187,\n",
       " 'know': 188,\n",
       " 'needs': 189,\n",
       " 'testing': 190,\n",
       " 'registered': 191,\n",
       " 'file': 192,\n",
       " 'software': 193,\n",
       " 'setup': 194,\n",
       " 'files': 195,\n",
       " 'discipline': 196,\n",
       " 'then': 197,\n",
       " 'password': 198,\n",
       " 'st': 199,\n",
       " 'requested': 200,\n",
       " 'currently': 201,\n",
       " 'assist': 202,\n",
       " 'review': 203,\n",
       " 'had': 204,\n",
       " 'consultant': 205,\n",
       " 'two': 206,\n",
       " 'additional': 207,\n",
       " 'updated': 208,\n",
       " 'content': 209,\n",
       " 'server': 210,\n",
       " 'device': 211,\n",
       " 'our': 212,\n",
       " 'section': 213,\n",
       " 'check': 214,\n",
       " 'connect': 215,\n",
       " 'following': 216,\n",
       " 'colleagues': 217,\n",
       " 'logged': 218,\n",
       " 'tickets': 219,\n",
       " 'get': 220,\n",
       " 'call': 221,\n",
       " 'changes': 222,\n",
       " 'purchased': 223,\n",
       " 'screen': 224,\n",
       " 'th': 225,\n",
       " 'members': 226,\n",
       " 'give': 227,\n",
       " 'period': 228,\n",
       " 'type': 229,\n",
       " 'infrastructure': 230,\n",
       " 'active': 231,\n",
       " 'communication': 232,\n",
       " 'part': 233,\n",
       " 'since': 234,\n",
       " 'regarding': 235,\n",
       " 'laptop': 236,\n",
       " 'unable': 237,\n",
       " 'seems': 238,\n",
       " 'requests': 239,\n",
       " 'done': 240,\n",
       " 'assistance': 241,\n",
       " 'changed': 242,\n",
       " 'were': 243,\n",
       " 'much': 244,\n",
       " 'want': 245,\n",
       " 'able': 246,\n",
       " 'sa': 247,\n",
       " 'job': 248,\n",
       " 'version': 249,\n",
       " 'intended': 250,\n",
       " 'license': 251,\n",
       " 'via': 252,\n",
       " 'groups': 253,\n",
       " 'complete': 254,\n",
       " 'urgent': 255,\n",
       " 'where': 256,\n",
       " 'credentials': 257,\n",
       " 'open': 258,\n",
       " 'description': 259,\n",
       " 'down': 260,\n",
       " 'expense': 261,\n",
       " 'trying': 262,\n",
       " 'installation': 263,\n",
       " 'think': 264,\n",
       " 'person': 265,\n",
       " 'machine': 266,\n",
       " 'investigate': 267,\n",
       " 'clients': 268,\n",
       " 'good': 269,\n",
       " 'room': 270,\n",
       " 'due': 271,\n",
       " 'still': 272,\n",
       " 'up': 273,\n",
       " 'only': 274,\n",
       " 'se': 275,\n",
       " 'accept': 276,\n",
       " 'failed': 277,\n",
       " 'permissions': 278,\n",
       " 'left': 279,\n",
       " 'week': 280,\n",
       " 'contact': 281,\n",
       " 'disk': 282,\n",
       " 'receiving': 283,\n",
       " 'environment': 284,\n",
       " 'fill': 285,\n",
       " 'center': 286,\n",
       " 'shared': 287,\n",
       " 'forward': 288,\n",
       " 'install': 289,\n",
       " 'him': 290,\n",
       " 'mandatory': 291,\n",
       " 'enter': 292,\n",
       " 'completed': 293,\n",
       " 'found': 294,\n",
       " 'related': 295,\n",
       " 'contract': 296,\n",
       " 'into': 297,\n",
       " 'receipts': 298,\n",
       " 'having': 299,\n",
       " 'morning': 300,\n",
       " 'allocation': 301,\n",
       " 'what': 302,\n",
       " 'entity': 303,\n",
       " 'ordered': 304,\n",
       " 'transfer': 305,\n",
       " 'video': 306,\n",
       " 'codes': 307,\n",
       " 'leader': 308,\n",
       " 'starting': 309,\n",
       " 'reference': 310,\n",
       " 'until': 311,\n",
       " 'document': 312,\n",
       " 'right': 313,\n",
       " 'using': 314,\n",
       " 'questions': 315,\n",
       " 'try': 316,\n",
       " 'share': 317,\n",
       " 'priority': 318,\n",
       " 'informed': 319,\n",
       " 'comments': 320,\n",
       " 'consideration': 321,\n",
       " 'would': 322,\n",
       " 'specialist': 323,\n",
       " 'cable': 324,\n",
       " 'keep': 325,\n",
       " 'summary': 326,\n",
       " 'way': 327,\n",
       " 'entered': 328,\n",
       " 'queue': 329,\n",
       " 'holiday': 330,\n",
       " 'cost': 331,\n",
       " 'looking': 332,\n",
       " 'computer': 333,\n",
       " 'while': 334,\n",
       " 'over': 335,\n",
       " 'connection': 336,\n",
       " 'side': 337,\n",
       " 'storage': 338,\n",
       " 'recipient': 339,\n",
       " 'than': 340,\n",
       " 'data': 341,\n",
       " 'address': 342,\n",
       " 'git': 343,\n",
       " 'getting': 344,\n",
       " 'off': 345,\n",
       " 'fix': 346,\n",
       " 'use': 347,\n",
       " 'library': 348,\n",
       " 'kb': 349,\n",
       " 'confidential': 350,\n",
       " 'kingdom': 351,\n",
       " 'free': 352,\n",
       " 'image': 353,\n",
       " 'option': 354,\n",
       " 'once': 355,\n",
       " 'street': 356,\n",
       " 'separate': 357,\n",
       " 'problems': 358,\n",
       " 'tool': 359,\n",
       " 'close': 360,\n",
       " 'installed': 361,\n",
       " 'hours': 362,\n",
       " 'links': 363,\n",
       " 'wants': 364,\n",
       " 'look': 365,\n",
       " 'tower': 366,\n",
       " 'timecard': 367,\n",
       " 'items': 368,\n",
       " 'resolved': 369,\n",
       " 'during': 370,\n",
       " 'perform': 371,\n",
       " 'expire': 372,\n",
       " 'them': 373,\n",
       " 'administration': 374,\n",
       " 'moment': 375,\n",
       " 'both': 376,\n",
       " 'connected': 377,\n",
       " 'got': 378,\n",
       " 'write': 379,\n",
       " 'require': 380,\n",
       " 'area': 381,\n",
       " 'made': 382,\n",
       " 'entries': 383,\n",
       " 'pc': 384,\n",
       " 'resources': 385,\n",
       " 'few': 386,\n",
       " 'extension': 387,\n",
       " 'teams': 388,\n",
       " 'app': 389,\n",
       " 'going': 390,\n",
       " 'requisition': 391,\n",
       " 'rejected': 392,\n",
       " 'technical': 393,\n",
       " 'total': 394,\n",
       " 'last': 395,\n",
       " 'feedback': 396,\n",
       " 'ref': 397,\n",
       " 'taken': 398,\n",
       " 'proceed': 399,\n",
       " 'without': 400,\n",
       " 'blvd': 401,\n",
       " 'based': 402,\n",
       " 'subscription': 403,\n",
       " 'decline': 404,\n",
       " 'must': 405,\n",
       " 'print': 406,\n",
       " 'resolution': 407,\n",
       " 'accordingly': 408,\n",
       " 'zone': 409,\n",
       " 'repository': 410,\n",
       " 'main': 411,\n",
       " 'etc': 412,\n",
       " 'automatically': 413,\n",
       " 'works': 414,\n",
       " 'colleague': 415,\n",
       " 'response': 416,\n",
       " 'ne': 417,\n",
       " 'everyone': 418,\n",
       " 'like': 419,\n",
       " 'attachments': 420,\n",
       " 'mentioned': 421,\n",
       " 'even': 422,\n",
       " 'printer': 423,\n",
       " 'return': 424,\n",
       " 'actions': 425,\n",
       " 'forms': 426,\n",
       " 'does': 427,\n",
       " 'port': 428,\n",
       " 'configuration': 429,\n",
       " 'why': 430,\n",
       " 'run': 431,\n",
       " 'remote': 432,\n",
       " 'allow': 433,\n",
       " 'incident': 434,\n",
       " 'member': 435,\n",
       " 'asap': 436,\n",
       " 'manage': 437,\n",
       " 'assets': 438,\n",
       " 'different': 439,\n",
       " 'absence': 440,\n",
       " 'move': 441,\n",
       " 'weeks': 442,\n",
       " 'backup': 443,\n",
       " 'employees': 444,\n",
       " 'mob': 445,\n",
       " 'reason': 446,\n",
       " 'removed': 447,\n",
       " 'maternity': 448,\n",
       " 'past': 449,\n",
       " 'record': 450,\n",
       " 'profile': 451,\n",
       " 'personal': 452,\n",
       " 'great': 453,\n",
       " 'broad': 454,\n",
       " 'notification': 455,\n",
       " 'within': 456,\n",
       " 'every': 457,\n",
       " 'myself': 458,\n",
       " 'key': 459,\n",
       " 'tomorrow': 460,\n",
       " 'closed': 461,\n",
       " 'event': 462,\n",
       " 'drive': 463,\n",
       " 'sorry': 464,\n",
       " 'here': 465,\n",
       " 'lot': 466,\n",
       " 'tasks': 467,\n",
       " 'role': 468,\n",
       " 'example': 469,\n",
       " 'line': 470,\n",
       " 'training': 471,\n",
       " 'haven': 472,\n",
       " 'count': 473,\n",
       " 'hesitate': 474,\n",
       " 'include': 475,\n",
       " 'level': 476,\n",
       " 'follow': 477,\n",
       " 'upload': 478,\n",
       " 'migration': 479,\n",
       " 'subsidiaries': 480,\n",
       " 'errors': 481,\n",
       " 'opportunity': 482,\n",
       " 'started': 483,\n",
       " 'notify': 484,\n",
       " 'steps': 485,\n",
       " 'size': 486,\n",
       " 'opinions': 487,\n",
       " 'raise': 488,\n",
       " 'planning': 489,\n",
       " 'rd': 490,\n",
       " 'consider': 491,\n",
       " 'visitor': 492,\n",
       " 'list': 493,\n",
       " 'appears': 494,\n",
       " 'country': 495,\n",
       " 'yet': 496,\n",
       " 'display': 497,\n",
       " 'important': 498,\n",
       " 'set': 499,\n",
       " 'matter': 500,\n",
       " 'msg': 501,\n",
       " 'solution': 502,\n",
       " 'believe': 503,\n",
       " 'step': 504,\n",
       " 'checked': 505,\n",
       " 'explorer': 506,\n",
       " 'messages': 507,\n",
       " 'database': 508,\n",
       " 'lost': 509,\n",
       " 'deleted': 510,\n",
       " 'whose': 511,\n",
       " 'pot': 512,\n",
       " 'wireless': 513,\n",
       " 'mine': 514,\n",
       " 'noticed': 515,\n",
       " 'ago': 516,\n",
       " 'provided': 517,\n",
       " 'anymore': 518,\n",
       " 'leaving': 519,\n",
       " 'wrong': 520,\n",
       " 'analysis': 521,\n",
       " 'upcoming': 522,\n",
       " 'visual': 523,\n",
       " 'running': 524,\n",
       " 'setting': 525,\n",
       " 'raised': 526,\n",
       " 'assignment': 527,\n",
       " 'cheers': 528,\n",
       " 'costs': 529,\n",
       " 'too': 530,\n",
       " 'host': 531,\n",
       " 'instead': 532,\n",
       " 'devices': 533,\n",
       " 'asking': 534,\n",
       " 'question': 535,\n",
       " 'unfortunately': 536,\n",
       " 'looks': 537,\n",
       " 'filled': 538,\n",
       " 'studio': 539,\n",
       " 'directly': 540,\n",
       " 'fixed': 541,\n",
       " 'yesterday': 542,\n",
       " 'very': 543,\n",
       " 'hardware': 544,\n",
       " 'notified': 545,\n",
       " 'ensure': 546,\n",
       " 'start': 547,\n",
       " 'control': 548,\n",
       " 'logging': 549,\n",
       " 'copy': 550,\n",
       " 'calendar': 551,\n",
       " 'multiple': 552,\n",
       " 'appreciate': 553,\n",
       " 'understand': 554,\n",
       " 'privileged': 555,\n",
       " 'granted': 556,\n",
       " 'weekly': 557,\n",
       " 'digital': 558,\n",
       " 'supplier': 559,\n",
       " 'notice': 560,\n",
       " 'button': 561,\n",
       " 'excel': 562,\n",
       " 'applications': 563,\n",
       " 'district': 564,\n",
       " 'default': 565,\n",
       " 'through': 566,\n",
       " 'restart': 567,\n",
       " 'addresses': 568,\n",
       " 'click': 569,\n",
       " 'already': 570,\n",
       " 'enable': 571,\n",
       " 'commercial': 572,\n",
       " 'public': 573,\n",
       " 'template': 574,\n",
       " 'intern': 575,\n",
       " 'pending': 576,\n",
       " 'pipeline': 577,\n",
       " 'offer': 578,\n",
       " 'sheet': 579,\n",
       " 'appropriate': 580,\n",
       " 'come': 581,\n",
       " 'permission': 582,\n",
       " 'resolve': 583,\n",
       " 'send': 584,\n",
       " 'inform': 585,\n",
       " 'times': 586,\n",
       " 'select': 587,\n",
       " 'recently': 588,\n",
       " 'progress': 589,\n",
       " 'query': 590,\n",
       " 'second': 591,\n",
       " 'sites': 592,\n",
       " 'design': 593,\n",
       " 'minutes': 594,\n",
       " 'everything': 595,\n",
       " 'accessing': 596,\n",
       " 'source': 597,\n",
       " 'however': 598,\n",
       " 'choose': 599,\n",
       " 'switch': 600,\n",
       " 'virtual': 601,\n",
       " 'calls': 602,\n",
       " 'search': 603,\n",
       " 'rooms': 604,\n",
       " 'creating': 605,\n",
       " 'short': 606,\n",
       " 'accountant': 607,\n",
       " 'another': 608,\n",
       " 'visible': 609,\n",
       " 'colombia': 610,\n",
       " 'owners': 611,\n",
       " 'dashboard': 612,\n",
       " 'ones': 613,\n",
       " 'survey': 614,\n",
       " 'book': 615,\n",
       " 'correct': 616,\n",
       " 'full': 617,\n",
       " 'solely': 618,\n",
       " 'certificate': 619,\n",
       " 'being': 620,\n",
       " 'licenses': 621,\n",
       " 'agile': 622,\n",
       " 'latest': 623,\n",
       " 'future': 624,\n",
       " 'regular': 625,\n",
       " 'immediately': 626,\n",
       " 'case': 627,\n",
       " 'almost': 628,\n",
       " 'called': 629,\n",
       " 'stop': 630,\n",
       " 'reminder': 631,\n",
       " 'maybe': 632,\n",
       " 'critical': 633,\n",
       " 'similar': 634,\n",
       " 'relevant': 635,\n",
       " 'before': 636,\n",
       " 'flow': 637,\n",
       " 'technician': 638,\n",
       " 'production': 639,\n",
       " 'path': 640,\n",
       " 'mon': 641,\n",
       " 'planned': 642,\n",
       " 'monitoring': 643,\n",
       " 'copying': 644,\n",
       " 'alert': 645,\n",
       " 'director': 646,\n",
       " 'coordinator': 647,\n",
       " 'os': 648,\n",
       " 'folders': 649,\n",
       " 'compliance': 650,\n",
       " 'least': 651,\n",
       " 'receipt': 652,\n",
       " 'instance': 653,\n",
       " 'performance': 654,\n",
       " 'ideas': 655,\n",
       " 'programme': 656,\n",
       " 'locations': 657,\n",
       " 'mb': 658,\n",
       " 'gets': 659,\n",
       " 'existing': 660,\n",
       " 'download': 661,\n",
       " 'creation': 662,\n",
       " 'architect': 663,\n",
       " 'properly': 664,\n",
       " 'months': 665,\n",
       " 'bit': 666,\n",
       " 'solve': 667,\n",
       " 'cr': 668,\n",
       " 'several': 669,\n",
       " 'legally': 670,\n",
       " 'final': 671,\n",
       " 'reported': 672,\n",
       " 'responsible': 673,\n",
       " 'saturday': 674,\n",
       " 'basis': 675,\n",
       " 'hearing': 676,\n",
       " 'release': 677,\n",
       " 'joining': 678,\n",
       " 'equipment': 679,\n",
       " 'guide': 680,\n",
       " 'tools': 681,\n",
       " 'invoice': 682,\n",
       " 'moved': 683,\n",
       " 'galaxy': 684,\n",
       " 'unit': 685,\n",
       " 'results': 686,\n",
       " 'amount': 687,\n",
       " 'encounter': 688,\n",
       " 'breakdown': 689,\n",
       " 'secure': 690,\n",
       " 'forecast': 691,\n",
       " 'liability': 692,\n",
       " 'lists': 693,\n",
       " 'locked': 694,\n",
       " 'apple': 695,\n",
       " 'machines': 696,\n",
       " 'processes': 697,\n",
       " 'sign': 698,\n",
       " 'mailing': 699,\n",
       " 'increase': 700,\n",
       " 'own': 701,\n",
       " 'something': 702,\n",
       " 'direct': 703,\n",
       " 'reset': 704,\n",
       " 'included': 705,\n",
       " 'followed': 706,\n",
       " 'daily': 707,\n",
       " 'space': 708,\n",
       " 'grade': 709,\n",
       " 'vacation': 710,\n",
       " 'replacement': 711,\n",
       " 'thread': 712,\n",
       " 'hold': 713,\n",
       " 'current': 714,\n",
       " 'contractor': 715,\n",
       " 'although': 716,\n",
       " 'snow': 717,\n",
       " 'submission': 718,\n",
       " 'end': 719,\n",
       " 'procedure': 720,\n",
       " 'prohibited': 721,\n",
       " 'replace': 722,\n",
       " 'fine': 723,\n",
       " 'disabled': 724,\n",
       " 'used': 725,\n",
       " 'imported': 726,\n",
       " 'policy': 727,\n",
       " 'otherwise': 728,\n",
       " 'options': 729,\n",
       " 'doing': 730,\n",
       " 'their': 731,\n",
       " 'confirmation': 732,\n",
       " 'info': 733,\n",
       " 'enough': 734,\n",
       " 'import': 735,\n",
       " 'sonar': 736,\n",
       " 'directory': 737,\n",
       " 'join': 738,\n",
       " 'plan': 739,\n",
       " 'returned': 740,\n",
       " 'history': 741,\n",
       " 'input': 742,\n",
       " 'scheduled': 743,\n",
       " 'necessarily': 744,\n",
       " 'save': 745,\n",
       " 'party': 746,\n",
       " 'virus': 747,\n",
       " 'title': 748,\n",
       " 'someone': 749,\n",
       " 'original': 750,\n",
       " 'addressee': 751,\n",
       " 'low': 752,\n",
       " 'timecards': 753,\n",
       " 'expired': 754,\n",
       " 'building': 755,\n",
       " 'press': 756,\n",
       " 'confirmed': 757,\n",
       " 'around': 758,\n",
       " 'correctly': 759,\n",
       " 'english': 760,\n",
       " 'program': 761,\n",
       " 'saved': 762,\n",
       " 'experience': 763,\n",
       " 'located': 764,\n",
       " 'keyboard': 765,\n",
       " 'configured': 766,\n",
       " 'established': 767,\n",
       " 'fie': 768,\n",
       " 'interns': 769,\n",
       " 'documentation': 770,\n",
       " 'warning': 771,\n",
       " 'later': 772,\n",
       " 'comment': 773,\n",
       " 'go': 774,\n",
       " 'projects': 775,\n",
       " 'automatic': 776,\n",
       " 'apply': 777,\n",
       " 'inventory': 778,\n",
       " 'ready': 779,\n",
       " 'menu': 780,\n",
       " 'anything': 781,\n",
       " 'become': 782,\n",
       " 'strictly': 783,\n",
       " 'better': 784,\n",
       " 'platform': 785,\n",
       " 'pass': 786,\n",
       " 'connecting': 787,\n",
       " 'solved': 788,\n",
       " 'wrote': 789,\n",
       " 'managed': 790,\n",
       " 'sow': 791,\n",
       " 'entire': 792,\n",
       " 'schedule': 793,\n",
       " 'collaboration': 794,\n",
       " 'mouse': 795,\n",
       " 'longer': 796,\n",
       " 'weekend': 797,\n",
       " 'accepted': 798,\n",
       " 'might': 799,\n",
       " 'shows': 800,\n",
       " 'expressed': 801,\n",
       " 'implemented': 802,\n",
       " 'browser': 803,\n",
       " 'assignee': 804,\n",
       " 'cum': 805,\n",
       " 'therefore': 806,\n",
       " 'board': 807,\n",
       " 'represent': 808,\n",
       " 'couple': 809,\n",
       " 'documents': 810,\n",
       " 'activate': 811,\n",
       " 'product': 812,\n",
       " 'build': 813,\n",
       " 'prod': 814,\n",
       " 'automation': 815,\n",
       " 'module': 816,\n",
       " 'recent': 817,\n",
       " 'internship': 818,\n",
       " 'disclosure': 819,\n",
       " 'according': 820,\n",
       " 'listed': 821,\n",
       " 'bellow': 822,\n",
       " 'above': 823,\n",
       " 'feel': 824,\n",
       " 'changing': 825,\n",
       " 'bad': 826,\n",
       " 'approvals': 827,\n",
       " 'together': 828,\n",
       " 'roaming': 829,\n",
       " 'given': 830,\n",
       " 'pro': 831,\n",
       " 'allocate': 832,\n",
       " 'fusion': 833,\n",
       " 'instructions': 834,\n",
       " 'previously': 835,\n",
       " 'coming': 836,\n",
       " 'far': 837,\n",
       " 'contribute': 838,\n",
       " 'happens': 839,\n",
       " 'wait': 840,\n",
       " 'recovery': 841,\n",
       " 'writing': 842,\n",
       " 'mails': 843,\n",
       " 'br': 844,\n",
       " 'sector': 845,\n",
       " 'sub': 846,\n",
       " 'customer': 847,\n",
       " 'understanding': 848,\n",
       " 'contracts': 849,\n",
       " 'occurred': 850,\n",
       " 'tab': 851,\n",
       " 'probably': 852,\n",
       " 'disable': 853,\n",
       " 'face': 854,\n",
       " 'holidays': 855,\n",
       " 'reach': 856,\n",
       " 'installing': 857,\n",
       " 'show': 858,\n",
       " 'guest': 859,\n",
       " 'web': 860,\n",
       " 'discuss': 861,\n",
       " 'detected': 862,\n",
       " 'requirements': 863,\n",
       " 'model': 864,\n",
       " 'self': 865,\n",
       " 'entry': 866,\n",
       " 'tv': 867,\n",
       " 'avoid': 868,\n",
       " 'contain': 869,\n",
       " 'known': 870,\n",
       " 'worked': 871,\n",
       " 'displayed': 872,\n",
       " 'export': 873,\n",
       " 'means': 874,\n",
       " 'meetings': 875,\n",
       " 'records': 876,\n",
       " 'experiencing': 877,\n",
       " 'belgrade': 878,\n",
       " 'restore': 879,\n",
       " 'continue': 880,\n",
       " 'requesting': 881,\n",
       " 'touch': 882,\n",
       " 'discussed': 883,\n",
       " 'domain': 884,\n",
       " 'making': 885,\n",
       " 'marked': 886,\n",
       " 'taking': 887,\n",
       " 'social': 888,\n",
       " 'modify': 889,\n",
       " 'authority': 890,\n",
       " 'false': 891,\n",
       " 'token': 892,\n",
       " 'present': 893,\n",
       " 'authentication': 894,\n",
       " 'performed': 895,\n",
       " 'portfolio': 896,\n",
       " 'subject': 897,\n",
       " 'responsibility': 898,\n",
       " 'empty': 899,\n",
       " 'impact': 900,\n",
       " 'hard': 901,\n",
       " 'awaiting': 902,\n",
       " 'ii': 903,\n",
       " 'accessible': 904,\n",
       " 'alt': 905,\n",
       " 'adapter': 906,\n",
       " 'category': 907,\n",
       " 'poll': 908,\n",
       " 'seem': 909,\n",
       " 'waiting': 910,\n",
       " 'ctrl': 911,\n",
       " 'rest': 912,\n",
       " 'badge': 913,\n",
       " 'sn': 914,\n",
       " 'text': 915,\n",
       " 'hey': 916,\n",
       " 'archive': 917,\n",
       " 'happened': 918,\n",
       " 'black': 919,\n",
       " 'appear': 920,\n",
       " 'special': 921,\n",
       " 'swap': 922,\n",
       " 'persons': 923,\n",
       " 'resource': 924,\n",
       " 'submitting': 925,\n",
       " 'apologies': 926,\n",
       " 'attach': 927,\n",
       " 'leavers': 928,\n",
       " 'nothing': 929,\n",
       " 'verify': 930,\n",
       " 'sd': 931,\n",
       " 'those': 932,\n",
       " 'idea': 933,\n",
       " 'payable': 934,\n",
       " 'anyone': 935,\n",
       " 'tm': 936,\n",
       " 'usually': 937,\n",
       " 'extended': 938,\n",
       " 'advice': 939,\n",
       " 'slow': 940,\n",
       " 'tax': 941,\n",
       " 'unavailable': 942,\n",
       " 'cause': 943,\n",
       " 'agreed': 944,\n",
       " 'android': 945,\n",
       " 'community': 946,\n",
       " 'merge': 947,\n",
       " 'generic': 948,\n",
       " 'treat': 949,\n",
       " 'backpack': 950,\n",
       " 'against': 951,\n",
       " 'requires': 952,\n",
       " 'activities': 953,\n",
       " 'reliance': 954,\n",
       " 'chrome': 955,\n",
       " 'entities': 956,\n",
       " 'none': 957,\n",
       " 'table': 958,\n",
       " 'won': 959,\n",
       " 'ports': 960,\n",
       " 'reject': 961,\n",
       " 'purposes': 962,\n",
       " 'really': 963,\n",
       " 'broken': 964,\n",
       " 'rule': 965,\n",
       " 'cables': 966,\n",
       " 'incorrect': 967,\n",
       " 'allocated': 968,\n",
       " 'usage': 969,\n",
       " 'mistake': 970,\n",
       " 'availability': 971,\n",
       " 'interface': 972,\n",
       " 'lines': 973,\n",
       " 'store': 974,\n",
       " 'extend': 975,\n",
       " 'frankfurt': 976,\n",
       " 'package': 977,\n",
       " 'result': 978,\n",
       " 'manually': 979,\n",
       " 'drop': 980,\n",
       " 'map': 981,\n",
       " 'administrators': 982,\n",
       " 'architecture': 983,\n",
       " 'wed': 984,\n",
       " 'month': 985,\n",
       " 'roles': 986,\n",
       " 'top': 987,\n",
       " 'profiles': 988,\n",
       " 'materials': 989,\n",
       " 'memory': 990,\n",
       " 'corresponding': 991,\n",
       " 'says': 992,\n",
       " 'confirm': 993,\n",
       " 'pages': 994,\n",
       " 'picture': 995,\n",
       " 'others': 996,\n",
       " 'expected': 997,\n",
       " 'approvers': 998,\n",
       " 'nj': 999,\n",
       " 'window': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43694, 50), (4855, 50))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_num_words) #Tokenizer is used to tokenize text\n",
    "tokenizer.fit_on_texts(raw_data.body) #Fit this to our corpus\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(raw_data.body) #'text to sequences converts the text to a list of indices\n",
    "x_train = pad_sequences(x_train, maxlen=50) #pad_sequences makes every sequence a fixed size list by padding with 0s \n",
    "x_test = tokenizer.texts_to_sequences(raw_test_data.body) \n",
    "x_test = pad_sequences(x_test, maxlen=50)\n",
    "\n",
    "x_train.shape, x_test.shape # Check the dimensions of x_train and x_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing the target vectors for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "unique_labels = list(raw_data.urgency.unique())\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical # This convert the labels to one-hot vectors(Dummies)\n",
    "\n",
    "y_train = np.array([unique_labels.index(i) for i in raw_data.urgency]) # Convert the word labels to indeces\n",
    "y_train = to_categorical(y_train) # Dummify the labels\n",
    "y_test = np.array([unique_labels.index(i) for i in raw_test_data.urgency])\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building and training an LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building an LSTM model\n",
    "model_lstm = Sequential() # Call Sequential to initialize a network\n",
    "model_lstm.add(Embedding(input_dim = max_num_words, \n",
    "                    input_length = seq_len, \n",
    "                    output_dim = embedding_size)) # Add an embedding layer which represents each unique token as a vector\n",
    "model_lstm.add(LSTM(30, return_sequences=True)) # Add an LSTM layer\n",
    "model_lstm.add(LSTM(10, return_sequences=True)) # Add an LSTM layer\n",
    "model_lstm.add(LSTM(5, return_sequences=False))\n",
    "model_lstm.add(Dense(4, activation='softmax')) # Add an ouput layer. Since classification, 3 nodes for 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 50, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 50, 30)            15720     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 50, 10)            1640      \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 5)                 320       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 24        \n",
      "=================================================================\n",
      "Total params: 1,017,704\n",
      "Trainable params: 1,017,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention the optimizer, Loss function and metrics to be computed\n",
    "model_lstm.compile(optimizer=adam,                  # 'Adam' is a variant of gradient descent technique\n",
    "              loss='categorical_crossentropy', # categorical_crossentropy for multi-class classification\n",
    "              metrics=['accuracy'])            # These metrics are computed for evaluating and stored in history\n",
    "\n",
    "# model_lstm.fit(x_train, y_train, epochs=5, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# model_lstm.save('model_lstm_V1.hdf5')\n",
    "model_lstm_V1_20_epochs = keras.models.load_model('model_lstm_V1.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and evaluation on test data\n",
    "1. Check the network output on test data. What do these values represent?\n",
    "2. Predict the class labels on test data\n",
    "2. Evaluate the model on test data\n",
    "\n",
    "Hint: Check model.predict, model.predict_classes, model.evaluate in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 50)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm_V1_20_epochs.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99947667e-01 1.13099723e-05 1.62411179e-05 2.47946173e-05]\n",
      " [9.92705100e-06 9.21769977e-01 6.01206236e-02 1.80995911e-02]\n",
      " [9.99944806e-01 1.21708099e-05 1.73272347e-05 2.57321353e-05]\n",
      " ...\n",
      " [9.99945045e-01 1.19486995e-05 1.68534534e-05 2.61700134e-05]\n",
      " [9.99921560e-01 1.71057891e-05 2.11598908e-05 4.00836689e-05]\n",
      " [9.99937773e-01 1.39852982e-05 1.90127885e-05 2.92914883e-05]]\n"
     ]
    }
   ],
   "source": [
    "test_prob = model_lstm_V1_20_epochs.predict(x_test)\n",
    "test_prob.shape\n",
    "print(test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9994767e-01, 1.1309972e-05, 1.6241118e-05, 2.4794617e-05],\n",
       "       [9.9270510e-06, 9.2176998e-01, 6.0120624e-02, 1.8099591e-02],\n",
       "       [9.9994481e-01, 1.2170810e-05, 1.7327235e-05, 2.5732135e-05],\n",
       "       [9.9995041e-01, 1.0544163e-05, 1.6460259e-05, 2.2691620e-05],\n",
       "       [1.5985581e-05, 8.9685416e-01, 8.0560334e-02, 2.2569416e-02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prob[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4855,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes = model_lstm_V1_20_epochs.predict_classes(x_test)\n",
    "test_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4855,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes = np.argmax(test_prob, axis=1)\n",
    "test_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 0, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4855/4855 [==============================] - 14s 3ms/step\n",
      "Test Loss: 0.3764079353571644\n",
      "Test Accuracy: 0.862821833161689\n"
     ]
    }
   ],
   "source": [
    "score = model_lstm_V1_20_epochs.evaluate(x_test, y_test)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3451    1   10    0]\n",
      " [   9  311  213   20]\n",
      " [   4  240  392   39]\n",
      " [   4   55   71   35]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), test_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Considering body, impact and catery for predicting the urgency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1771780292976"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_approach2 = x_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1776735919840"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(x_train_approach2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_approach2 = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1776735919920"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(x_test_approach2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Impact \n",
    "\n",
    "    a. Dummifying the unique labels in impact column and concatenating the same with x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((43694, 50), (4855, 50))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "unique_labels_impact = list(raw_data.impact.unique())\n",
    "#print(unique_labels_impact)\n",
    "\n",
    "impactDummy = np.array([unique_labels_impact.index(i) for i in raw_data.impact]) # Convert the word labels to indeces\n",
    "impactDummy = to_categorical(impactDummy) # Dummify the labels\n",
    "print(type(impactDummy))\n",
    "\n",
    "x_train_approach2.shape, x_test_approach2.shape # Check the dimensions of x_train_approach2 and x_test_approach2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_approach2 = np.concatenate((x_train_approach2, impactDummy), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43694, 55), (4855, 50))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_approach2.shape, x_test_approach2.shape # Check the dimensions of x_train and x_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b. Dummifying the unique labels in impact column and concatenating the same with x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_test_labels_impact = list(raw_test_data.impact.unique())\n",
    "#print(unique_labels_impact)\n",
    "\n",
    "impactDummy = np.array([unique_test_labels_impact.index(i) for i in raw_test_data.impact]) # Convert the word labels to indeces\n",
    "impactDummy = to_categorical(impactDummy) # Dummify the labels\n",
    "type(impactDummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_approach2 = np.concatenate((x_test_approach2, impactDummy), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43694, 55), (4855, 55))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_approach2.shape, x_test_approach2.shape # Check the dimensions of x_train and x_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Category\n",
    "    a. Dummifying the unique labels in category column and concatenating the same with x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels_category = list(raw_data.category.unique())\n",
    "#print(unique_labels_category)\n",
    "\n",
    "category_Dummy = np.array([unique_labels_category.index(i) for i in raw_data.category]) # Convert the word labels to indeces\n",
    "category_Dummy = to_categorical(category_Dummy) # Dummify the labels\n",
    "type(category_Dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_approach2 = np.concatenate((x_train_approach2, category_Dummy), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b. Dummifying the unique labels in category column and concatenating the same with x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_test_labels_category = list(raw_test_data.category.unique())\n",
    "#print(unique_labels_category)\n",
    "\n",
    "category_Dummy = np.array([unique_test_labels_category.index(i) for i in raw_test_data.category]) # Convert the word labels to indeces\n",
    "category_Dummy = to_categorical(category_Dummy) # Dummify the labels\n",
    "type(category_Dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_approach2 = np.concatenate((x_test_approach2, category_Dummy), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43694, 68), (4855, 67))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_approach2.shape, x_test_approach2.shape # Check the dimensions of x_train and x_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pad_sequence so that x_train and x_test will have same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_approach2 = pad_sequences(x_train_approach2, maxlen=70)\n",
    "x_test_approach2 = pad_sequences(x_test_approach2, maxlen=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43694, 70), (4855, 70))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_approach2.shape, x_test_approach2.shape # Check the dimensions of x_train and x_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach2: Building and training an LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_words = 10000\n",
    "seq_len_approach2 = 70\n",
    "embedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building an LSTM model\n",
    "model_lstm_approach2 = Sequential() # Call Sequential to initialize a network\n",
    "model_lstm_approach2.add(Embedding(input_dim = max_num_words, \n",
    "                    input_length = seq_len_approach2, \n",
    "                    output_dim = embedding_size)) # Add an embedding layer which represents each unique token as a vector\n",
    "model_lstm_approach2.add(LSTM(30, return_sequences=True)) # Add an LSTM layer\n",
    "model_lstm_approach2.add(LSTM(10, return_sequences=True)) # Add an LSTM layer\n",
    "model_lstm_approach2.add(LSTM(5, return_sequences=False))\n",
    "model_lstm_approach2.add(Dense(4, activation='softmax')) # Add an ouput layer. Since classification, 3 nodes for 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 70, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 70, 30)            15720     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 70, 10)            1640      \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 5)                 320       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 24        \n",
      "=================================================================\n",
      "Total params: 1,017,704\n",
      "Trainable params: 1,017,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm_approach2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention the optimizer, Loss function and metrics to be computed\n",
    "model_lstm_approach2.compile(optimizer=adam,                  # 'Adam' is a variant of gradient descent technique\n",
    "              loss='categorical_crossentropy', # categorical_crossentropy for multi-class classification\n",
    "              metrics=['accuracy'])            # These metrics are computed for evaluating and stored in history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lstm_approach2.fit(x_train_approach2, y_train, epochs=3, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# model_lstm_approach2.save('model_lstm_V3.hdf5')\n",
    "model_lstm_V2_with_impact_category_3_epochs = keras.models.load_model('model_lstm_V3.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach2: Prediction and evaluation on test data\n",
    "1. Check the network output on test data. What do these values represent?\n",
    "2. Predict the class labels on test data\n",
    "2. Evaluate the model on test data\n",
    "\n",
    "Hint: Check model.predict, model.predict_classes, model.evaluate in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 70)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm_V2_with_impact_category_3_epochs.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9829572e-01 7.1178738e-04 7.9652417e-04 1.9602239e-04]\n",
      " [2.2686180e-03 3.9962882e-01 4.8040229e-01 1.1770027e-01]\n",
      " [9.9829572e-01 7.1171846e-04 7.9647213e-04 1.9601904e-04]\n",
      " ...\n",
      " [9.9829584e-01 7.1170466e-04 7.9646008e-04 1.9601402e-04]\n",
      " [9.9829608e-01 7.1157143e-04 7.9635507e-04 1.9599704e-04]\n",
      " [9.9829441e-01 7.1234017e-04 7.9704478e-04 1.9618784e-04]]\n"
     ]
    }
   ],
   "source": [
    "test_prob_approach2 = model_lstm_V2_with_impact_category_3_epochs.predict(x_test_approach2)\n",
    "test_prob_approach2.shape\n",
    "print(test_prob_approach2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.98295724e-01, 7.11787376e-04, 7.96524168e-04, 1.96022389e-04],\n",
       "       [2.26861797e-03, 3.99628818e-01, 4.80402291e-01, 1.17700271e-01],\n",
       "       [9.98295724e-01, 7.11718458e-04, 7.96472130e-04, 1.96019042e-04],\n",
       "       [9.98294652e-01, 7.12210662e-04, 7.96940469e-04, 1.96138499e-04],\n",
       "       [2.25384627e-03, 3.96106422e-01, 4.84644324e-01, 1.16995454e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prob_approach2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4855,)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes_approach2 = model_lstm_V2_with_impact_category_3_epochs.predict_classes(x_test_approach2)\n",
    "test_classes_approach2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4855,)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes_approach2 = np.argmax(test_prob_approach2, axis=1)\n",
    "test_classes_approach2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes_approach2[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach2: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4855/4855 [==============================] - 18s 4ms/step\n",
      "Test Loss: 0.30524546695234356\n",
      "Test Accuracy: 0.8543769309130315\n"
     ]
    }
   ],
   "source": [
    "score_approach2 = model_lstm_V2_with_impact_category_3_epochs.evaluate(x_test_approach2, y_test)\n",
    "print('Test Loss:', score_approach2[0])\n",
    "print('Test Accuracy:', score_approach2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3459    3    0    0]\n",
      " [   8   52  493    0]\n",
      " [  10   28  637    0]\n",
      " [   7   11  147    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), test_classes_approach2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predicted by first model for first 30 tickets: \n",
      " [0 1 0 0 1 0 1 0 0 2 0 2 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0 2 1 2] \n",
      "\n",
      "Class predicted by second model (approach2) for first 30 tickets: \n",
      " [0 2 0 0 2 0 2 0 0 2 0 2 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Class predicted by first model for first 30 tickets: \\n\", test_classes[:30], \"\\n\")\n",
    "\n",
    "print(\"Class predicted by second model (approach2) for first 30 tickets: \\n\", test_classes_approach2[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class wise probabilities for first 10 tickets predicted by first model: \n",
      " [[9.99947667e-01 1.13099723e-05 1.62411179e-05 2.47946173e-05]\n",
      " [9.92705100e-06 9.21769977e-01 6.01206236e-02 1.80995911e-02]\n",
      " [9.99944806e-01 1.21708099e-05 1.73272347e-05 2.57321353e-05]\n",
      " [9.99950409e-01 1.05441632e-05 1.64602588e-05 2.26916200e-05]\n",
      " [1.59855808e-05 8.96854162e-01 8.05603340e-02 2.25694161e-02]\n",
      " [9.99944806e-01 1.21456605e-05 1.83488646e-05 2.47250282e-05]\n",
      " [1.11780892e-05 8.65991831e-01 1.10134572e-01 2.38624923e-02]\n",
      " [9.99944091e-01 1.19399165e-05 1.73598237e-05 2.65845138e-05]\n",
      " [9.99938011e-01 1.30618937e-05 1.89897055e-05 2.99402582e-05]\n",
      " [2.13179865e-05 6.86056241e-02 9.27409410e-01 3.96369537e-03]] \n",
      "\n",
      "\n",
      "Class wise probabilities for first 10 tickets predicted by second model (approach2): \n",
      " [[9.98295724e-01 7.11787376e-04 7.96524168e-04 1.96022389e-04]\n",
      " [2.26861797e-03 3.99628818e-01 4.80402291e-01 1.17700271e-01]\n",
      " [9.98295724e-01 7.11718458e-04 7.96472130e-04 1.96019042e-04]\n",
      " [9.98294652e-01 7.12210662e-04 7.96940469e-04 1.96138499e-04]\n",
      " [2.25384627e-03 3.96106422e-01 4.84644324e-01 1.16995454e-01]\n",
      " [9.98295248e-01 7.11993081e-04 7.96702341e-04 1.96091481e-04]\n",
      " [2.28905608e-03 3.99544805e-01 4.80501473e-01 1.17664747e-01]\n",
      " [9.98292387e-01 7.13162590e-04 7.97995424e-04 1.96384179e-04]\n",
      " [9.98292029e-01 7.13353511e-04 7.98181223e-04 1.96423818e-04]\n",
      " [2.35382002e-03 3.91034007e-01 4.90361720e-01 1.16250455e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Class wise probabilities for first 10 tickets predicted by first model: \\n\", test_prob[:10], \"\\n\")\n",
    "print()\n",
    "print(\"Class wise probabilities for first 10 tickets predicted by second model (approach2): \\n\", test_prob_approach2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First model</td>\n",
       "      <td>0.862822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Second model</td>\n",
       "      <td>0.854377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Accuracy\n",
       "0  First model   0.862822\n",
       "1  Second model  0.854377"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Model': ['First model' , 'Second model'], \\\n",
    "        'Accuracy': [score[1], score_approach2[1]]}\n",
    "Final_Output =pd.DataFrame.from_dict(data)#, orient='index')\n",
    "Final_Output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
